{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "import sys\n",
    "\n",
    "config_ini = \"/Users/isammohdibrahim/Documents/Dev/running-with-oliver-cromwell/DNAseq-short-variant-discovery/preparing_inputs/config-localmac.ini\"\n",
    "\n",
    "def nl():\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(conf_ini=\"config.ini\"):\n",
    "    # Read config.ini file\n",
    "    print(\"Reading keys in config.ini ...\")\n",
    "    conf = ConfigParser()\n",
    "    conf.read(conf_ini)\n",
    "    conf_keys = {}\n",
    "\n",
    "    conf_keys['groupname'] = conf['RUNTIME']['groupname']\n",
    "    conf_keys['input_file'] = conf['RUNTIME']['input_file']\n",
    "    conf_keys['ref_version'] = conf['RUNTIME']['ref_version']\n",
    "    conf_keys['raw_file_dir'] = conf['RUNTIME']['raw_file_dir'].rstrip('/').rstrip('\\\\')\n",
    "    conf_keys['send_email_for_all'] = conf.getboolean('RUNTIME', 'send_email_for_all')\n",
    "\n",
    "    conf_keys['interval_file'] = conf['RUNTIME']['interval_file']\n",
    "\n",
    "    conf_keys['email'] = conf['USERCONFIG']['email']\n",
    "    conf_keys['base_output_dir'] = conf['USERCONFIG']['base_output_dir'].rstrip('/').rstrip('\\\\')\n",
    "    conf_keys['base_output_dir'] += \"/\" + conf_keys['groupname']\n",
    "\n",
    "    conf_keys['n_dir'] = conf_keys['raw_file_dir'] + \"/\" + conf['RAWFILEDIRS']['n_dir'].rstrip('/').rstrip('\\\\')\n",
    "    conf_keys['t_dir'] = conf_keys['raw_file_dir'] + \"/\" + conf['RAWFILEDIRS']['t_dir'].rstrip('/').rstrip('\\\\')\n",
    "    conf_keys['pon_dir'] = conf_keys['raw_file_dir'] + \"/\" + conf['RAWFILEDIRS']['pon_dir'].rstrip('/').rstrip('\\\\')\n",
    "\n",
    "    conf_keys['ref_dir'] = conf['SERVERCONFIG']['ref_dir'].rstrip('/').rstrip('\\\\')\n",
    "    conf_keys['gatk_docker'] = conf['SERVERCONFIG']['gatk_docker']\n",
    "\n",
    "    os.makedirs(conf_keys['base_output_dir'], exist_ok=True)\n",
    "    print(f\"Generated JSONs will be saved to: {conf_keys['base_output_dir']}\")\n",
    "    nl()\n",
    "    return conf_keys\n",
    "\n",
    "conf_keys = load_config(config_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_inputcsv(input_file):\n",
    "    # read input csv\n",
    "    print(f\"Loading input file: {input_file}\")\n",
    "    input_df = pd.read_csv(input_file)\n",
    "\n",
    "    # check for required columns\n",
    "    required_cols = ['readgroup', 'sample_name', 'subject_id', 'sample_type', 'absolute_path_to_fq1', 'absolute_path_to_fq2', 'library_name', 'platform_unit', 'sequence_date', 'sequence_platform', 'sequence_center']\n",
    "\n",
    "    if not set(required_cols).issubset(input_df.columns):\n",
    "        missing_cols = list(set(required_cols) - set(input_df.columns))\n",
    "        print(f\"Missing columns: {missing_cols}\")\n",
    "        sys.exit()\n",
    "    nl()\n",
    "    return input_df\n",
    "\n",
    "input_df = load_inputcsv(conf_keys['input_file'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to check if the interval file (`interval_loc`) used in the next block matches the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def def_refs(conf_keys):\n",
    "    ref_version = conf_keys['ref_version']\n",
    "    interval_file = conf_keys['interval_file']\n",
    "    ref_dir = conf_keys['ref_dir']\n",
    "    pon_dir = conf_keys['pon_dir']\n",
    "    groupname = conf_keys['groupname']\n",
    "\n",
    "    ref_refs = {}\n",
    "\n",
    "    # switching of references depending on ref_version\n",
    "    if ref_version == \"b37\":\n",
    "        if interval_file:\n",
    "            ref_refs['interval_loc']=interval_file \n",
    "        else:\n",
    "            ref_refs['interval_loc'] = f\"{ref_dir}/Agilent_SureSelect_Human_All_Exon_V4/S03723314_Regions.converted.bed\"\n",
    "            print(f\"`interval_file` not defined in config.ini. The following default interval file will be used instead: {ref_refs['interval_loc']}\")\n",
    "\n",
    "        ref_refs['ref_fasta'] = f\"{ref_dir}/b37/human_g1k_v37_decoy.fasta\"\n",
    "        ref_refs['ref_fai'] = f\"{ref_dir}/b37/human_g1k_v37_decoy.fasta.fai\"\n",
    "        ref_refs['ref_dict'] = f\"{ref_dir}/b37/human_g1k_v37_decoy.dict\"\n",
    "        \n",
    "\n",
    "        ref_refs['pon'] = f\"{pon_dir}/{groupname}_pon.vcf\"\n",
    "        ref_refs['pon_idx'] = f\"{pon_dir}/{groupname}_pon.vcf.idx\"\n",
    "\n",
    "        ref_refs['gnomad'] = f\"{ref_dir}/b37/af-only-gnomad.raw.sites.vcf\"\n",
    "        ref_refs['gnomad_idx'] = f\"{ref_dir}/b37/af-only-gnomad.raw.sites.vcf.idx\"\n",
    "        ref_refs['variants_for_contamination'] = f\"{ref_dir}/b37/small_exac_common_3.vcf\"\n",
    "        ref_refs['variants_for_contamination_idx'] = f\"{ref_dir}/b37/small_exac_common_3.vcf.idx\"\n",
    "        ref_refs['funco_data_source'] = f\"{ref_dir}/b37/funcotator_dataSources.v1.7.20200521s.tar.gz\"\n",
    "    elif ref_version == \"hg38\":\n",
    "        # only WGS version of interval list on disk for hg38\n",
    "        if interval_file:\n",
    "            ref_refs['interval_loc'] = interval_file \n",
    "        else:\n",
    "            ref_refs['interval_loc'] = f\"{ref_dir}/hg38/wgs_calling_regions.hg38.interval_list\"\n",
    "            print(f\"`interval_file` not defined in config.ini. The following default interval file will be used instead: {ref_refs['interval_loc']}\")\n",
    "\n",
    "        ref_refs['ref_fasta'] = f\"{ref_dir}/hg38/Homo_sapiens_assembly38.fasta\"\n",
    "        ref_refs['ref_fai'] = f\"{ref_dir}/hg38/Homo_sapiens_assembly38.fasta.fai\"\n",
    "        ref_refs['ref_dict'] = f\"{ref_dir}/hg38/Homo_sapiens_assembly38.dict\"\n",
    "\n",
    "        ref_refs['pon'] = f\"{{pon_dir}}/pon/1000g_pon.hg38.vcf.gz\"\n",
    "        ref_refs['pon_idx'] = f\"{{pon_dir}}/pon/1000g_pon.hg38.vcf.gz.tbi\"\n",
    "\n",
    "        ref_refs['gnomad'] = f\"{ref_dir}/hg38/af-only-gnomad.hg38.vcf.gz\"\n",
    "        ref_refs['gnomad_idx'] = f\"{ref_dir}/hg38/af-only-gnomad.hg38.vcf.gz.tbi\"\n",
    "        ref_refs['variants_for_contamination'] = f\"{ref_dir}/hg38/small_exac_common_3.hg38.vcf.gz\"\n",
    "        ref_refs['variants_for_contamination_idx'] = f\"{ref_dir}/hg38/small_exac_common_3.hg38.vcf.gz.tbi\"\n",
    "        ref_refs['funco_data_source'] = f\"{ref_dir}/hg38/funcotator_dataSources.v1.7.20200521s.tar.gz\"\n",
    "\n",
    "    nl()\n",
    "    return ref_refs\n",
    "\n",
    "ref_refs = def_refs(conf_keys)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1. SCMA input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_scma(conf_keys, input_df):\n",
    "    base_output_dir = conf_keys['base_output_dir']\n",
    "    send_email_for_all = conf_keys['send_email_for_all']\n",
    "    email = conf_keys['email']\n",
    "\n",
    "    print(\"Generating input for SCMA ...\")\n",
    "    scma_output_dir=f'{base_output_dir}/scma'\n",
    "    os.makedirs(scma_output_dir, exist_ok=True)\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "        i = index + 1\n",
    "        if send_email_for_all == False and i == input_df.shape[0]:\n",
    "            send_email = True\n",
    "        else:\n",
    "            send_email = send_email_for_all\n",
    "\n",
    "        output = {\n",
    "                \"seqConvMarkAdapt.readgroup_name\": row['readgroup'],\n",
    "                \"seqConvMarkAdapt.sample_name\": row['sample_name'],\n",
    "                \"seqConvMarkAdapt.fastq_1\": row['absolute_path_to_fq1'],\n",
    "                \"seqConvMarkAdapt.fastq_2\": row['absolute_path_to_fq2'],\n",
    "                \"seqConvMarkAdapt.library_name\": row['library_name'],\n",
    "                \"seqConvMarkAdapt.platform_unit\": row['platform_unit'],\n",
    "                \"seqConvMarkAdapt.run_date\": row['sequence_date'],\n",
    "                \"seqConvMarkAdapt.platform_name\": row['sequence_platform'],\n",
    "                \"seqConvMarkAdapt.sequencing_center\": row['sequence_center'],\n",
    "                \"seqConvMarkAdapt.make_fofn\": True,\n",
    "                \"seqConvMarkAdapt.send_email\": send_email,  \n",
    "                \"seqConvMarkAdapt.email\": email,  \n",
    "            }\n",
    "        \n",
    "        with open(f'{scma_output_dir}/{row[\"readgroup\"]}.json', 'w') as outfile:\n",
    "            json.dump(output, outfile, indent=4)\n",
    "        output = {}\n",
    "\n",
    "    print(f'{i} input files for SCMA saved to: {scma_output_dir}')\n",
    "    nl()\n",
    "    return\n",
    "\n",
    "if input_df['absolute_path_to_fq2'].dropna().size == 0:\n",
    "    print('SCMA input gen not run because of single fq file path')\n",
    "else:\n",
    "    gen_scma(conf_keys, input_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2. Bam2uBam input\n",
    "- will only run if `input_df` only has all nulls in `absolute_path_to_fq2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_b2ma(conf_keys, input_df):\n",
    "    base_output_dir = conf_keys['base_output_dir']\n",
    "    send_email_for_all = conf_keys['send_email_for_all']\n",
    "    email = conf_keys['email']\n",
    "\n",
    "    print(\"Generating input for Bam2uMarkAdapt ...\")\n",
    "    b2ma_output_dir=f'{base_output_dir}/b2ma'\n",
    "    os.makedirs(b2ma_output_dir, exist_ok=True)\n",
    "\n",
    "    for index, row in input_df.iterrows():\n",
    "        i = index + 1\n",
    "        if send_email_for_all == False and i == input_df.size[0]:\n",
    "            send_email = True\n",
    "        else:\n",
    "            send_email = bool(send_email_for_all)\n",
    "\n",
    "        output = {\n",
    "                \"Bam2uMarkAdapt.input_bam\": row['absolute_path_to_fq1'],\n",
    "                \"Bam2uMarkAdapt.send_email\": send_email,  \n",
    "                \"Bam2uMarkAdapt.email\": email,  \n",
    "            }\n",
    "        \n",
    "        with open(f'{b2ma_output_dir}/{row[\"readgroup\"]}.json', 'w') as outfile:\n",
    "            json.dump(output, outfile, indent=4)\n",
    "        output = {}\n",
    "\n",
    "    print(f'{i} input files for b2ma saved to: {b2ma_output_dir}')\n",
    "    nl()\n",
    "    return\n",
    "\n",
    "if input_df['absolute_path_to_fq2'].dropna().size == 0:\n",
    "    gen_b2ma(conf_keys, input_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Pre-processing\n",
    "- no input needs to be generated. Pipeline will use output from SCMA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. PoN input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = input_df.query('sample_type == \"N\"')\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below was changed a bit for JGAD301, because the BAM file names were based on the converted bam2ubam files, and thus do not follow the usual sample_name format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pon(conf_keys, input_df, ref_refs):\n",
    "    base_output_dir = conf_keys['base_output_dir']\n",
    "    n_dir = conf_keys['n_dir']\n",
    "    gatk_docker = conf_keys['gatk_docker']\n",
    "    groupname = conf_keys['groupname']\n",
    "    email = conf_keys['email']\n",
    "    send_email_for_all = conf_keys['send_email_for_all']\n",
    "    ref_version = conf_keys['ref_version']\n",
    "    \n",
    "    ref_fasta = ref_refs['ref_fasta']\n",
    "    ref_fai = ref_refs['ref_fai']\n",
    "    ref_dict = ref_refs['ref_dict']\n",
    "    gnomad = ref_refs['gnomad']\n",
    "    gnomad_idx = ref_refs['gnomad_idx']\n",
    "    interval_loc = ref_refs['interval_loc']\n",
    "\n",
    "    print(\"Generating input for Panel of Normals ...\")\n",
    "\n",
    "    pon_output_dir = f'{base_output_dir}/m2'\n",
    "    os.makedirs(pon_output_dir, exist_ok=True)\n",
    "\n",
    "    n = input_df.query('sample_type == \"N\"')\n",
    "    # samples_n = n['sample_name'].sort_values().unique().tolist()\n",
    "    samples_n = n['library_name'].sort_values().unique().tolist()\n",
    "    n_bams = [f'{n_dir}/{n}_WES.{ref_version}.bam' for n in samples_n]\n",
    "    n_bais = [f'{n_dir}/{n}_WES.{ref_version}.bai' for n in samples_n]\n",
    "    # n_bams = [f'{n_dir}/{n}.{ref_version}.bam' for n in samples_n]\n",
    "    # n_bais = [f'{n_dir}/{n}.{ref_version}.bai' for n in samples_n]\n",
    "\n",
    "    input = {\n",
    "        \"Mutect2_Panel.gatk_docker\": gatk_docker,\n",
    "\n",
    "        \"Mutect2_Panel.pon_name\": f\"{groupname}_pon\",\n",
    "        \"Mutect2_Panel.normal_bams\": n_bams,\n",
    "        \"Mutect2_Panel.normal_bais\": n_bais,\n",
    "\n",
    "\n",
    "        \"Mutect2_Panel.ref_fasta\": ref_fasta,\n",
    "        \"Mutect2_Panel.ref_fai\": ref_fai,\n",
    "        \"Mutect2_Panel.ref_dict\": ref_dict,\n",
    "        \"Mutect2_Panel.scatter_count\": 1,\n",
    "        \n",
    "        \"Mutect2_Panel.gnomad\": gnomad,\n",
    "        \"Mutect2_Panel.gnomad_idx\": gnomad_idx,\n",
    "\n",
    "        \"Mutect2_Panel.intervals\":interval_loc,\n",
    "        \"Mutect2_Panel.email\": email,\n",
    "        \"Mutect2_Panel.Mutect2.filter_mem\": 2000,\n",
    "        \"Mutect2_Panel.send_email\": True if send_email_for_all else False\n",
    "    }\n",
    "\n",
    "    with open(f'{pon_output_dir}/pon.json', 'w') as f:\n",
    "        json.dump(input, f, indent=4)\n",
    "\n",
    "    print('PoN input saved to:')\n",
    "    print(f'{pon_output_dir}/pon.json')\n",
    "    nl()\n",
    "    return\n",
    "\n",
    "gen_pon(conf_keys, input_df, ref_refs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Mutect2 input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also needs to be modified for JGAD301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_m2(conf_keys, input_df, ref_refs):\n",
    "    base_output_dir = conf_keys['base_output_dir']\n",
    "    n_dir = conf_keys['n_dir']\n",
    "    t_dir = conf_keys['t_dir']\n",
    "    gatk_docker = conf_keys['gatk_docker']\n",
    "    email = conf_keys['email']\n",
    "    ref_version = conf_keys['ref_version']\n",
    "    \n",
    "    ref_fasta = ref_refs['ref_fasta']\n",
    "    ref_fai = ref_refs['ref_fai']\n",
    "    ref_dict = ref_refs['ref_dict']\n",
    "    gnomad = ref_refs['gnomad']\n",
    "    gnomad_idx = ref_refs['gnomad_idx']\n",
    "    interval_loc = ref_refs['interval_loc']    \n",
    "    pon = ref_refs['pon']    \n",
    "    pon_idx = ref_refs['pon_idx']    \n",
    "    funco_data_source = ref_refs['funco_data_source']    \n",
    "    variants_for_contamination = ref_refs['variants_for_contamination']    \n",
    "    variants_for_contamination_idx = ref_refs['variants_for_contamination_idx']    \n",
    "\n",
    "    print(\"Generating input for m2 ...\")\n",
    "    m2_output_dir = f'{base_output_dir}/m2'\n",
    "\n",
    "    i = 0\n",
    "    os.makedirs(m2_output_dir, exist_ok=True)\n",
    "\n",
    "    # get list of subject ids\n",
    "    subject_ids = input_df[\"subject_id\"].unique()\n",
    "    t = input_df.query('sample_type == \"T\"')\n",
    "    n = input_df.query('sample_type == \"N\"')\n",
    "\n",
    "    # parse through list and get tumor and normal sample id for each one\n",
    "    for s in subject_ids:\n",
    "        i+= 1\n",
    "        \n",
    "        # this just attaches a send email job upon completion of the last workflow in the group\n",
    "        send_email = True if i == len(subject_ids) else False\n",
    "        # send_email = True\n",
    "        \n",
    "        # n_sample = n.query(f'subject_id == \"{s}\" ')[\"sample_name\"].values[0]\n",
    "        # t_sample = t.query(f'subject_id == \"{s}\" ')[\"sample_name\"].values[0]\n",
    "        # JGAD301 uses library name\n",
    "        n_sample = n.query(f'subject_id == \"{s}\" ')[\"library_name\"].values[0]\n",
    "        t_sample = t.query(f'subject_id == \"{s}\" ')[\"library_name\"].values[0]\n",
    "        m2_input = {\n",
    "            \n",
    "            # \"Mutect2.normal_reads\": f\"{n_dir}/{n_sample}.{ref_version}.bam\",\n",
    "            # \"Mutect2.normal_reads_index\": f\"{n_dir}/{n_sample}.{ref_version}.bai\",\n",
    "            # \"Mutect2.tumor_reads\": f\"{t_dir}/{t_sample}.{ref_version}.bam\",\n",
    "            # \"Mutect2.tumor_reads_index\": f\"{t_dir}/{t_sample}.{ref_version}.bai\",\n",
    "\n",
    "            # JGAD301 bam file names are a bit different too\n",
    "            \"Mutect2.normal_reads\": f\"{n_dir}/{n_sample}_WES.{ref_version}.bam\",\n",
    "            \"Mutect2.normal_reads_index\": f\"{n_dir}/{n_sample}_WES.{ref_version}.bai\",\n",
    "            \"Mutect2.tumor_reads\": f\"{t_dir}/{t_sample}_WES.{ref_version}.bam\",\n",
    "            \"Mutect2.tumor_reads_index\": f\"{t_dir}/{t_sample}_WES.{ref_version}.bai\",\n",
    "            \n",
    "            \"Mutect2.gatk_docker\": gatk_docker,\n",
    "    \n",
    "            \"Mutect2.intervals\": interval_loc,\n",
    "            \"Mutect2.scatter_count\": 12,\n",
    "            \"Mutect2.m2_extra_args\": \" -ip 100 \",\n",
    "            \"Mutect2.split_intervals_extra_args\": \" --subdivision-mode BALANCING_WITHOUT_INTERVAL_SUBDIVISION --min-contig-size 1000000 \",\n",
    "\n",
    "            \"Mutect2.filter_funcotations\": \"True\",\n",
    "            \"Mutect2.funco_reference_version\": \"hg19\" if ref_version == \"b37\" else ref_version, \n",
    "            # funcotator sources for all references are in here\n",
    "            \"Mutect2.funco_data_sources_tar_gz\": funco_data_source,\n",
    "\n",
    "            \"Mutect2.ref_fasta\": ref_fasta, \n",
    "            \"Mutect2.ref_fai\": ref_fai, \n",
    "            \"Mutect2.ref_dict\": ref_dict, \n",
    "\n",
    "            \"Mutect2.pon\": pon, \n",
    "            \"Mutect2.pon_idx\": pon_idx, \n",
    "\n",
    "            \"Mutect2.gnomad\": gnomad, \n",
    "            \"Mutect2.gnomad_idx\": gnomad_idx, \n",
    "            \"Mutect2.variants_for_contamination\": variants_for_contamination, \n",
    "            \"Mutect2.variants_for_contamination_idx\": variants_for_contamination_idx, \n",
    "\n",
    "            \"Mutect2.run_funcotator\": True,\n",
    "            \"Mutect2.run_orientation_bias_mixture_model_filter\": True,\n",
    "            \"Mutect2.send_email\": send_email,\n",
    "            \"Mutect2.email\": email,\n",
    "        }\n",
    "        with open(f'{m2_output_dir}/{s}.json', 'w') as f:\n",
    "            json.dump(m2_input, f, indent=4)\n",
    "    print(f'{i} input JSON saved to:')\n",
    "    print(f'{m2_output_dir}')\n",
    "    nl()\n",
    "    return\n",
    "\n",
    "gen_m2(conf_keys, input_df, ref_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== INPUT GEN END ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
