[RUNTIME] 
; these usually change with each batch of data
groupname = crc_sub1 
; this is usually a reference to the accession or source of the data
input_file = /Users/isammohdibrahim/Documents/Dev/running-with-oliver-cromwell/subsample.csv
ref_version = b37 
; option of b37 or hg38 
raw_file_dir = /home/imibrahim/crc_sub1
; parent directory where the BAM, PON, and MAF files are expected to be
;; note: the pipeline does not move these files here automatically, the files must be moved manually
send_email_for_all = True 
; sends email for each workflow that completes, this can get overwhelming if processing a large batch of data. By default, an email with always be sent when the last workflow inputted has completed
;; value is either True or False
interval_file = 
;; path to the interval file. Leave empty to use the default interval files for b37 and hg38 (WGS)


[USERCONFIG] 
; user specific settings: you would usually only change this the first time you get this conf
email = isambmi@hawaii.edu
base_output_dir = /Users/isammohdibrahim/Documents/Dev/running-with-oliver-cromwell/output
; location where JSONs generated by this script will be output
;; the script will save all JSONs in a subdirectory of the same groupname e.g. /base/output/dir/groupname

[RAWFILEDIRS] 
; directory structure where the raw files are expected to be on the server: this would also usually only be set once, unless you change directory structures for each run
n_dir = bam/b37-n 
; e.g. /raw/file/dir/bam/b37-n
t_dir = bam/b37-t
pon_dir = pon 
; e.g. /raw/file/dir/pon

[SERVERCONFIG] 
; server specific run: these would rarely change
gatk_docker = arashi-gatk-426
; this refers to the container (singularity/docker) used for the pipeline. These containers are located at /home/imibrahim/SIFs
ref_dir = /home/imibrahim/refs
; this is location of the reference files on ARASHI. Don't change unless intending to use the pipeline with own set of references not defined here